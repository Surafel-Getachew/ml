{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# mulitclass classification - softmax"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def my_softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    sm = ez/np.sum(ez)\n",
    "    return sm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# make  dataset for example\n",
    "centers = [[-5, 2], [-2, -2], [1, 2], [5, -2]]\n",
    "X_train, y_train = make_blobs(n_samples=2000, centers=centers, cluster_std=1.0,random_state=30)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(25,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(15,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4,activation=\"softmax\")\n",
    "])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-21 14:53:59.600601: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-03-21 14:53:59.601064: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# model.fit(X_train,y_train,epochs=10)\n",
    "model.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=10\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-21 14:54:16.515773: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-21 14:54:16.991336: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63/63 [==============================] - 1s 5ms/step - loss: 0.9252\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.3509\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1605\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0992\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0745\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0613\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0534\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0479\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0436\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0397\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e359f40>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "p_nonpreferred = model.predict(X_train)\n",
    "print(p_nonpreferred [:2])\n",
    "print(\"largest value\", np.max(p_nonpreferred), \"smallest value\", np.min(p_nonpreferred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " 1/63 [..............................] - ETA: 14s"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-21 15:09:50.960099: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n",
      "[[9.4512915e-03 1.2309392e-03 9.6986818e-01 1.9449603e-02]\n",
      " [9.9541157e-01 4.3963902e-03 7.7274126e-05 1.1478692e-04]]\n",
      "largest value 0.9999987 smallest value 6.8088424e-11\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prefered"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "preferred_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(25,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(15,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(4,activation=\"linear\"),\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "preferred_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "preferred_model.fit(X_train,y_train,epochs=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "24/63 [==========>...................] - ETA: 0s - loss: 1.1430"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-21 15:11:31.289130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63/63 [==============================] - 0s 5ms/step - loss: 0.9058\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.4361\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1867\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.1001\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0681\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 0s 4ms/step - loss: 0.0540\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0460\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0408\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0371\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 0s 5ms/step - loss: 0.0341\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2803061c0>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "p_preferred = preferred_model.predict(X_train)\n",
    "print(f\"two example output vectors:\\n {p_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(p_preferred), \"smallest value\", np.min(p_preferred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "63/63 [==============================] - 0s 2ms/step\n",
      "two example output vectors:\n",
      " [[-0.70801497 -1.0307316   4.1313014  -0.10231146]\n",
      " [ 8.591696    1.828611   -3.0394797  -4.762278  ]]\n",
      "largest value 16.35105 smallest value -9.243338\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-21 15:11:45.902785: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The output predictions are not probabilities! If the desired output are probabilities, the output should be be processed by a softmax."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "sm_preferred = tf.nn.softmax(p_preferred).numpy()\n",
    "print(f\"two example output vectors:\\n {sm_preferred[:2]}\")\n",
    "print(\"largest value\", np.max(sm_preferred), \"smallest value\", np.min(sm_preferred))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "two example output vectors:\n",
      " [[7.6958807e-03 5.5731949e-03 9.7262788e-01 1.4103014e-02]\n",
      " [9.9883515e-01 1.1543125e-03 8.8743891e-06 1.5846630e-06]]\n",
      "largest value 1.0 smallest value 7.664755e-12\n",
      "m -0.70801497\n",
      "my_softmax 1.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To select the most likely category, the softmax is not required. One can find the index of the largest output using np.argmax()."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for i in range(5):\n",
    "    print( f\"{p_preferred[i]}, category: {np.argmax(p_preferred[i])}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-0.70801497 -1.0307316   4.1313014  -0.10231146], category: 2\n",
      "[ 8.591696   1.828611  -3.0394797 -4.762278 ], category: 0\n",
      "[ 6.13415    2.0857482 -2.2284007 -4.050535 ], category: 0\n",
      "[-1.3693347  4.494403  -0.2579732 -2.935954 ], category: 1\n",
      "[ 1.9146984  -0.64026713  7.1323204  -3.9856515 ], category: 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit ('ml_env': venv)"
  },
  "interpreter": {
   "hash": "32ccf6d8fd4b6578a07243d614f9f887f5db17c8a40014981f62dc87df55ea75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}