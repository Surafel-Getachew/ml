{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# multiclass classification excercise for hand written digit recognition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_data():\n",
    "    X = np.load(\"data/X.npy\")\n",
    "    y = np.load(\"data/y.npy\")\n",
    "    return X, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X,y = load_data()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "print(f\"The frist elment of x is {X[0]}\")\n",
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The frist elment of x is [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  8.56059680e-06\n",
      "  1.94035948e-06 -7.37438725e-04 -8.13403799e-03 -1.86104473e-02\n",
      " -1.87412865e-02 -1.87572508e-02 -1.90963542e-02 -1.64039011e-02\n",
      " -3.78191381e-03  3.30347316e-04  1.27655229e-05  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  1.16421569e-04  1.20052179e-04\n",
      " -1.40444581e-02 -2.84542484e-02  8.03826593e-02  2.66540339e-01\n",
      "  2.73853746e-01  2.78729541e-01  2.74293607e-01  2.24676403e-01\n",
      "  2.77562977e-02 -7.06315478e-03  2.34715414e-04  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.28335523e-17 -3.26286765e-04 -1.38651604e-02\n",
      "  8.15651552e-02  3.82800381e-01  8.57849775e-01  1.00109761e+00\n",
      "  9.69710638e-01  9.30928598e-01  1.00383757e+00  9.64157356e-01\n",
      "  4.49256553e-01 -5.60408259e-03 -3.78319036e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  5.10620915e-06\n",
      "  4.36410675e-04 -3.95509940e-03 -2.68537241e-02  1.00755014e-01\n",
      "  6.42031710e-01  1.03136838e+00  8.50968614e-01  5.43122379e-01\n",
      "  3.42599738e-01  2.68918777e-01  6.68374643e-01  1.01256958e+00\n",
      "  9.03795598e-01  1.04481574e-01 -1.66424973e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.59875260e-05\n",
      " -3.10606987e-03  7.52456076e-03  1.77539831e-01  7.92890120e-01\n",
      "  9.65626503e-01  4.63166079e-01  6.91720680e-02 -3.64100526e-03\n",
      " -4.12180405e-02 -5.01900656e-02  1.56102907e-01  9.01762651e-01\n",
      "  1.04748346e+00  1.51055252e-01 -2.16044665e-02  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.87012352e-05 -6.40931373e-04\n",
      " -3.23305249e-02  2.78203465e-01  9.36720163e-01  1.04320956e+00\n",
      "  5.98003217e-01 -3.59409041e-03 -2.16751770e-02 -4.81021923e-03\n",
      "  6.16566793e-05 -1.23773318e-02  1.55477482e-01  9.14867477e-01\n",
      "  9.20401348e-01  1.09173902e-01 -1.71058007e-02  0.00000000e+00\n",
      "  0.00000000e+00  1.56250000e-04 -4.27724104e-04 -2.51466503e-02\n",
      "  1.30532561e-01  7.81664862e-01  1.02836583e+00  7.57137601e-01\n",
      "  2.84667194e-01  4.86865128e-03 -3.18688725e-03  0.00000000e+00\n",
      "  8.36492601e-04 -3.70751123e-02  4.52644165e-01  1.03180133e+00\n",
      "  5.39028101e-01 -2.43742611e-03 -4.80290033e-03  0.00000000e+00\n",
      "  0.00000000e+00 -7.03635621e-04 -1.27262443e-02  1.61706648e-01\n",
      "  7.79865383e-01  1.03676705e+00  8.04490400e-01  1.60586724e-01\n",
      " -1.38173339e-02  2.14879493e-03 -2.12622549e-04  2.04248366e-04\n",
      " -6.85907627e-03  4.31712963e-04  7.20680947e-01  8.48136063e-01\n",
      "  1.51383408e-01 -2.28404366e-02  1.98971950e-04  0.00000000e+00\n",
      "  0.00000000e+00 -9.40410539e-03  3.74520505e-02  6.94389110e-01\n",
      "  1.02844844e+00  1.01648066e+00  8.80488426e-01  3.92123945e-01\n",
      " -1.74122413e-02 -1.20098039e-04  5.55215142e-05 -2.23907271e-03\n",
      " -2.76068376e-02  3.68645493e-01  9.36411169e-01  4.59006723e-01\n",
      " -4.24701797e-02  1.17356610e-03  1.88929739e-05  0.00000000e+00\n",
      "  0.00000000e+00 -1.93511951e-02  1.29999794e-01  9.79821705e-01\n",
      "  9.41862388e-01  7.75147704e-01  8.73632241e-01  2.12778350e-01\n",
      " -1.72353349e-02  0.00000000e+00  1.09937426e-03 -2.61793751e-02\n",
      "  1.22872879e-01  8.30812662e-01  7.26501773e-01  5.24441863e-02\n",
      " -6.18971913e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -9.36563862e-03  3.68349741e-02  6.99079299e-01\n",
      "  1.00293583e+00  6.05704402e-01  3.27299224e-01 -3.22099249e-02\n",
      " -4.83053002e-02 -4.34069138e-02 -5.75151144e-02  9.55674190e-02\n",
      "  7.26512627e-01  6.95366966e-01  1.47114481e-01 -1.20048679e-02\n",
      " -3.02798203e-04  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00 -6.76572712e-04 -6.51415556e-03  1.17339359e-01\n",
      "  4.21948410e-01  9.93210937e-01  8.82013974e-01  7.45758734e-01\n",
      "  7.23874268e-01  7.23341725e-01  7.20020340e-01  8.45324959e-01\n",
      "  8.31859739e-01  6.88831870e-02 -2.77765012e-02  3.59136710e-04\n",
      "  7.14869281e-05  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.53186275e-04  3.17353553e-04 -2.29167177e-02\n",
      " -4.14402914e-03  3.87038450e-01  5.04583435e-01  7.74885876e-01\n",
      "  9.90037446e-01  1.00769478e+00  1.00851440e+00  7.37905042e-01\n",
      "  2.15455291e-01 -2.69624864e-02  1.32506127e-03  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  2.36366422e-04\n",
      " -2.26031454e-03 -2.51994485e-02 -3.73889910e-02  6.62121228e-02\n",
      "  2.91134498e-01  3.23055726e-01  3.06260315e-01  8.76070942e-02\n",
      " -2.50581917e-02  2.37438725e-04  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  6.20939216e-18  6.72618320e-04 -1.13151411e-02\n",
      " -3.54641066e-02 -3.88214912e-02 -3.71077412e-02 -1.33524928e-02\n",
      "  9.90964718e-04  4.89176960e-05  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 400)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(f\"The frist element of y is {y[0,0]}\")\n",
    "print(f\"The last element of y is {y[-1,0]}\")\n",
    "y.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The frist element of y is 0\n",
      "The last element of y is 9\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create the layers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.Input(shape=(400,)),\n",
    "    tf.keras.layers.Dense(25,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(15,activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(10,activation=\"linear\"),\n",
    "])\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 25)                10025     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 15)                390       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                160       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,575\n",
      "Trainable params: 10,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "W1 shape = (400, 25), b1 shape = (25,)\n",
      "W2 shape = (25, 15), b2 shape = (15,)\n",
      "W3 shape = (15, 10), b3 shape = (10,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Specify loss function"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "model.fit(X,y,epochs=10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2023-03-22 23:59:02.577576: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-03-22 23:59:02.780155: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "157/157 [==============================] - 2s 7ms/step - loss: 1.5335\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.6021\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 1s 7ms/step - loss: 0.4212\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3522\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3119\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2833\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.2583\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2378\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2237\n",
      "Epoch 10/10\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.2112\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x282868eb0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction\n",
    "To make a prediction, use Keras predict. Below, X[1015] contains an image of a two."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "image_of_two = X[1015]\n",
    "prediction = model.predict(image_of_two.reshape(1,400))\n",
    "\n",
    "print(f\"Predicting a two {prediction}\")\n",
    "print(f\"Largest prediction index {np.argmax(prediction)}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 8ms/step\n",
      "Predicting a two [[-2.967952    2.1764088   3.3227303   1.9276437  -3.8685791  -3.0152483\n",
      "  -3.6274042   1.392863   -0.38376337 -0.07060297]]\n",
      "Largest prediction index 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The largest output is prediction[2], indicating the predicted digit is a '2'. If the problem only requires a selection, that is sufficient. Use NumPy argmax to select it. If the problem requires a probability, a softmax is required:\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " predicting a Two. Probability vector: \n",
      "[[1.0446490e-03 1.7911740e-01 5.6361032e-01 1.3966914e-01 4.2445620e-04\n",
      "  9.9639094e-04 5.4022414e-04 8.1817873e-02 1.3844240e-02 1.8935334e-02]]\n",
      "Total of predictions: 1.000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To return an integer representing the predicted target, you want the index of the largest probability. This is accomplished with the Numpy argmax function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "np.argmax(prediction_p): 2\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.12 64-bit ('ml_env': venv)"
  },
  "interpreter": {
   "hash": "32ccf6d8fd4b6578a07243d614f9f887f5db17c8a40014981f62dc87df55ea75"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}